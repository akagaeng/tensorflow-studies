{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. ML Application & Tips\n",
    "- [강의 동영상 7-1](https://youtu.be/1jPjVoDV_uo): Learning rate, data preprocessing, overfitting\n",
    "- [강의 동영상 7-2](https://youtu.be/KVv1nMSlPzY): Learning and test data sets\n",
    "- [강의 슬라이드 7-1, 7-2](https://hunkim.github.io/ml/lec7.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1. Learning rate, data preprocessing, overfitting\n",
    "\n",
    "### Gradient descent 알고리즘에서 learning rate $\\alpha$\n",
    "\n",
    "- learning rate를 잘 정하는 것이 중요\n",
    "- learning rate를 쉽게 설명하면 경사면을 내려가는 정도라고 생각하면 되는데...\n",
    "- ***learning rate가 크면***\n",
    "  + 스텝이 커져서 최저점에 도달하지 못하고 좌우로 왔다갔다하게 됨\n",
    "  + 최저점에 가까이에 가지도 못하고 cost가 계속 큰 값으로 이동하게 될 수 있음(숫자가 아닌 값이 찍히기 시작함...)\n",
    "  + ***Overshooting!*** 이라고 한다\n",
    "- ***learning rate가 작으면***\n",
    "  + 스텝이 작아서 최저점에 도달하는 시간이 너무 오래 걸린다.\n",
    "  + local minima에 갇힐 수 있다. 즉, 우리가 찾고자 하는 global minima를 찾지 못할 수 있다.\n",
    "  + cost를 계속 찍어보면서 너무 적게 변한다면 이 값을 증가시켜본다!\n",
    "-learning rate를 정하는 명확한 정답은 없다!\n",
    "  + cost function 관찰\n",
    "  + cost function의 변화를 지켜보면서 적절한 값을 향해 cost function이 감소하는지 확인하기\n",
    "    - cost function의 값이 커진다면 learning rate를 작게 하고, \n",
    "    - cost function의 값이 너무 조금씩 작아진다면 learning rate를 크게 한다\n",
    "\n",
    "![learning-rate](images/lec7/learning-rate.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data (X) preprocessing for gradient descent\n",
    "- 데이터의 편차가 큰 경우에 minimize가 잘 안될 수 있어서 ***normalize***가 필요함\n",
    "![data-preprocessing](images/lec7/data-preprocessing.png)\n",
    "- Original data  >  zero-centered data(데이터의 중심을 0,0으로 이동)  >  normalized data(값을 일정 범위 내로 한정시킴)\n",
    "- 방법: standardization!\n",
    "\n",
    "#### Standardization\n",
    "- 수식\n",
    "  + $x_{j}'=\\frac{x_{j}-\\mu_{j}}{\\sigma_{j}}$\n",
    "- python: \n",
    "```python\n",
    "X_std[:,0] = (X[:,0] - X[:,0].mean()) / X[:,0].std()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overfitting문제 해결법!\n",
    "#### Overfitting이란? \n",
    "- 머신러닝의 가장 큰 문제!!!!!\n",
    "- 학습 데이터에 ***너무 딱 맞는 모델*** !\n",
    "\n",
    "학습 데이터로 테스트하면 결과가 잘 나오지만, 실제로는 학습데이터가 아닌 새로운 데이터로 결과값을 예측해야하므로 너무 학습데이터에만 딱 맞는 모델은 좋지 않다.(아래 우측 그림 model2)\n",
    "\n",
    "![overfitting](images/lec7/overfitting.png)\n",
    "\n",
    "#### Overfitting 문제 해결법\n",
    "- more training data!\n",
    "- reduce the number of features!\n",
    "- regularization! (아래)\n",
    "\n",
    "#### Regularization\n",
    "- weight가 커질수록 H(x)의 선이 구부러지면서 overfitting이 일어나게 되는데, weight가 너무 큰 값을 가지 않도록 한다!\n",
    "\n",
    "$$\n",
    "Cost(Loss) = \\frac{1}{N}\\cdot \\sum D(S(W X_{i}+b), L_{i}) + \\lambda \\sum W^2\n",
    "$$\n",
    "- 뒷 항의 $\\lambda$가 regularization strength인데, \n",
    "  + $\\lambda$가 0인 경우: regularization 적용 x\n",
    "  + $\\lambda$가 큰 수인 경우: regularization 더 중요하게 적용 \n",
    "- tensorflow로 구현: `l2reg = lambda * tf.reduce_sum(tf.square(W)) # 이 때 lambda는 임의의 수 ex) 0.001`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2. Learning and test data sets\n",
    "\n",
    "ML 모델이 얼마나 잘 동작하는지를 확인하는 방법에 대해서 알아봄\n",
    "\n",
    "### Performance evaluation: is this good?\n",
    "\n",
    "- data set으로 model을 학습시킨 다음 이 data set으로 답을 물어보면 100% 정확하게 답이 나옴!\n",
    "  + 나쁜 방법!\n",
    "- 전체 data set을 training set과 test set으로 나누어서 training set은 학습을 시키고, test set으로는 예측값과 실제 값을 비교하는 용도로 사용한다.\n",
    "  + training set을 또다시 training/validation 으로 나누어서 training으로 학습시키고 validation으로 검증하는 과정을 tuning 과정이라고 한다.\n",
    "\n",
    "![training-validation-test-sets](images/lec7/training-validation-test-sets.png)\n",
    "\n",
    "#### Online Learning\n",
    "- data set이 많은 경우 이를 일부로 나누어서, 이 중 일부씩 기존 학습 데이터에 추가해가며 학습시키는 방법\n",
    "- 새로운 데이터가 추가될 경우 이를 누적하여 학습시킬 수 있어 좋음\n",
    "- ex) 100만건의 data set이 있는 경우 이를 10만건씩 학습시키는 학습. 단, 기존 학습데이터는 남아있어야 한다!\n",
    "\n",
    "### MNIST Dataset\n",
    "\n",
    "유명한 MNIST dataset의 구성\n",
    "- 대부분 데이터들이 training set과 test set으로 나누어져 있으며, 각각은 데이터와 label로 구성되어 있다.\n",
    "\n",
    "training set\n",
    "- **train-images-idx3-ubyte.gz**:  training set images (9912422 bytes)\n",
    "- **train-labels-idx1-ubyte.gz**:  training set labels (28881 bytes) \n",
    "\n",
    "test set\n",
    "- **t10k-images-idx3-ubyte.gz**:   test set images (1648877 bytes) \n",
    "- **t10k-labels-idx1-ubyte.gz**:   test set labels (4542 bytes)\n",
    "\n",
    "### Accuracy\n",
    "- 실제 데이터의 $y$값(label)과 모델이 예측한 값($\\bar{y}$)이 얼마나 정확한지 알아보는 것\n",
    "- 현재 이미지 인식 분야의 정확도는 95% 이상"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
