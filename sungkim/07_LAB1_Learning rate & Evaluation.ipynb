{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [LAB 7-1] Learning rate, Evaluation\n",
    "\n",
    "- [실습 동영상 7-1](https://youtu.be/oSJfejG2C3w): Learning rate, Evaluation\n",
    "- [실습 슬라이드 7](https://docs.google.com/presentation/d/1cVwqMpERToATs1JGYps0F3MLARP8OAlw6ZIe-lpPHYs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Test datasets\n",
    "\n",
    "이제는 무조건 training set과 test set을 나누어서 작업!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### learning_rate=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4.0953927 [[ 0.97045416 -0.638319   -0.440653  ]\n",
      " [-1.8165996   0.41645554 -0.61373717]\n",
      " [-0.07345881 -0.6208512   0.31327146]]\n",
      "100 0.80565584 [[-0.2288093  -0.72015613  0.8404474 ]\n",
      " [-0.61640465 -0.75389576 -0.6435805 ]\n",
      " [ 0.00515791  0.12292323 -0.50911963]]\n",
      "200 0.64239776 [[-0.83111346 -0.74117     1.4637656 ]\n",
      " [-0.53902    -0.7375802  -0.7372804 ]\n",
      " [ 0.16834496  0.13839284 -0.687776  ]]\n",
      "Prediction: [2 2 2]\n",
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x_data = [[1, 2, 1],\n",
    "          [1, 3, 2],\n",
    "          [1, 3, 4],\n",
    "          [1, 5, 5],\n",
    "          [1, 7, 5],\n",
    "          [1, 2, 5],\n",
    "          [1, 6, 6],\n",
    "          [1, 7, 7]]\n",
    "y_data = [[0, 0, 1],\n",
    "          [0, 0, 1],\n",
    "          [0, 0, 1],\n",
    "          [0, 1, 0],\n",
    "          [0, 1, 0],\n",
    "          [0, 1, 0],\n",
    "          [1, 0, 0],\n",
    "          [1, 0, 0]]\n",
    "\n",
    "\n",
    "# Evaluation our model using this test dataset\n",
    "x_test = [[2, 1, 1],\n",
    "          [3, 1, 2],\n",
    "          [3, 3, 4]]\n",
    "y_test = [[0, 0, 1],\n",
    "          [0, 0, 1],\n",
    "          [0, 0, 1]]\n",
    "\n",
    "X = tf.placeholder(\"float\", [None, 3]) # train할 때와 test할 때의 데이터를 다르게 입력 (X: x_data / X: x_test)\n",
    "Y = tf.placeholder(\"float\", [None, 3]) # 이게 placeholder를 사용하는 이유! \n",
    "W = tf.Variable(tf.random_normal([3, 3]))\n",
    "b = tf.Variable(tf.random_normal([3]))\n",
    "\n",
    "hypothesis = tf.nn.softmax(tf.matmul(X, W)+b)\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(hypothesis), axis=1))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "# Correct prediction test model\n",
    "prediction = tf.argmax(hypothesis, 1)\n",
    "is_correct = tf.equal(prediction, tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "# Launch graph\n",
    "with tf.Session() as sess:\n",
    "    # initialize tensorflow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(201):\n",
    "        cost_val, W_val, _ = sess.run([cost, W, optimizer], feed_dict={X: x_data, Y: y_data})\n",
    "        if step % 100 == 0:\n",
    "            print(step, cost_val, W_val)\n",
    "\n",
    "    # predict\n",
    "    print(\"Prediction:\", sess.run(prediction, feed_dict={X: x_test}))\n",
    "    # Calculate the accuracy\n",
    "    print(\"Accuracy: \", sess.run(accuracy, feed_dict={X: x_test, Y: y_test}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### learning_rate=[0.1, 10.0, 1e-100] 인 경우 케이스 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate= 0.1 \n",
      "\n",
      "step:  0 \n",
      "cost:  5.236453 \n",
      "W: \n",
      " [[-0.6574761   0.57657224  0.8407245 ]\n",
      " [ 0.8380136   0.6963624   1.291002  ]\n",
      " [ 1.4481996  -0.8285357   0.08477776]] \n",
      "\n",
      "step:  50 \n",
      "cost:  0.60171413 \n",
      "W: \n",
      " [[-0.9964413   0.70958716  1.0466748 ]\n",
      " [ 0.96509     0.9692966   0.8909916 ]\n",
      " [ 0.7905054   0.29510847 -0.38117203]] \n",
      "\n",
      "step:  100 \n",
      "cost:  0.55947727 \n",
      "W: \n",
      " [[-1.1906787   0.6793575   1.2711419 ]\n",
      " [ 1.0548108   0.90949374  0.8610738 ]\n",
      " [ 0.7771321   0.3763802  -0.4490699 ]] \n",
      "\n",
      "step:  150 \n",
      "cost:  0.5319862 \n",
      "W: \n",
      " [[-1.3604889   0.6600006   1.4603089 ]\n",
      " [ 1.0780892   0.91137487  0.8359135 ]\n",
      " [ 0.8207003   0.39021757 -0.5064751 ]] \n",
      "\n",
      "step:  200 \n",
      "cost:  0.5097165 \n",
      "W: \n",
      " [[-1.5182364  0.6523783  1.6256788]\n",
      " [ 1.0862275  0.9200321  0.8191175]\n",
      " [ 0.8744266  0.3916894 -0.561673 ]] \n",
      "\n",
      "Prediction: [2 2 2]\n",
      "Accuracy:  1.0\n",
      "\n",
      "\n",
      "learning_rate= 10.0 \n",
      "\n",
      "step:  0 \n",
      "cost:  7.3156333 \n",
      "W: \n",
      " [[  1.7456031   4.952132   -5.5093093]\n",
      " [ 15.83849    16.634905  -33.386547 ]\n",
      " [ 16.356192   17.68999   -34.012455 ]] \n",
      "\n",
      "step:  50 \n",
      "cost:  nan \n",
      "W: \n",
      " [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]] \n",
      "\n",
      "step:  100 \n",
      "cost:  nan \n",
      "W: \n",
      " [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]] \n",
      "\n",
      "step:  150 \n",
      "cost:  nan \n",
      "W: \n",
      " [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]] \n",
      "\n",
      "step:  200 \n",
      "cost:  nan \n",
      "W: \n",
      " [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]] \n",
      "\n",
      "Prediction: [0 0 0]\n",
      "Accuracy:  0.0\n",
      "\n",
      "\n",
      "learning_rate= 1e-100 \n",
      "\n",
      "step:  0 \n",
      "cost:  7.060543 \n",
      "W: \n",
      " [[-0.42266357 -0.01143161 -1.0920125 ]\n",
      " [ 2.1882906  -1.0445029  -0.46492505]\n",
      " [-1.3170903  -1.167421    0.77721435]] \n",
      "\n",
      "step:  50 \n",
      "cost:  7.060543 \n",
      "W: \n",
      " [[-0.42266357 -0.01143161 -1.0920125 ]\n",
      " [ 2.1882906  -1.0445029  -0.46492505]\n",
      " [-1.3170903  -1.167421    0.77721435]] \n",
      "\n",
      "step:  100 \n",
      "cost:  7.060543 \n",
      "W: \n",
      " [[-0.42266357 -0.01143161 -1.0920125 ]\n",
      " [ 2.1882906  -1.0445029  -0.46492505]\n",
      " [-1.3170903  -1.167421    0.77721435]] \n",
      "\n",
      "step:  150 \n",
      "cost:  7.060543 \n",
      "W: \n",
      " [[-0.42266357 -0.01143161 -1.0920125 ]\n",
      " [ 2.1882906  -1.0445029  -0.46492505]\n",
      " [-1.3170903  -1.167421    0.77721435]] \n",
      "\n",
      "step:  200 \n",
      "cost:  7.060543 \n",
      "W: \n",
      " [[-0.42266357 -0.01143161 -1.0920125 ]\n",
      " [ 2.1882906  -1.0445029  -0.46492505]\n",
      " [-1.3170903  -1.167421    0.77721435]] \n",
      "\n",
      "Prediction: [0 0 0]\n",
      "Accuracy:  0.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x_data = [[1, 2, 1],\n",
    "          [1, 3, 2],\n",
    "          [1, 3, 4],\n",
    "          [1, 5, 5],\n",
    "          [1, 7, 5],\n",
    "          [1, 2, 5],\n",
    "          [1, 6, 6],\n",
    "          [1, 7, 7]]\n",
    "y_data = [[0, 0, 1],\n",
    "          [0, 0, 1],\n",
    "          [0, 0, 1],\n",
    "          [0, 1, 0],\n",
    "          [0, 1, 0],\n",
    "          [0, 1, 0],\n",
    "          [1, 0, 0],\n",
    "          [1, 0, 0]]\n",
    "\n",
    "\n",
    "# Evaluation our model using this test dataset\n",
    "x_test = [[2, 1, 1],\n",
    "          [3, 1, 2],\n",
    "          [3, 3, 4]]\n",
    "y_test = [[0, 0, 1],\n",
    "          [0, 0, 1],\n",
    "          [0, 0, 1]]\n",
    "\n",
    "X = tf.placeholder(\"float\", [None, 3]) # train할 때와 test할 때의 데이터를 다르게 입력 (X: x_data / X: x_test)\n",
    "Y = tf.placeholder(\"float\", [None, 3]) # 이게 placeholder를 사용하는 이유! \n",
    "W = tf.Variable(tf.random_normal([3, 3]))\n",
    "b = tf.Variable(tf.random_normal([3]))\n",
    "\n",
    "learning_rates = [0.1, 10.0, 1e-100]\n",
    "for learning_rate in learning_rates:\n",
    "    print(\"learning_rate=\", learning_rate, \"\\n\");\n",
    "\n",
    "    hypothesis = tf.nn.softmax(tf.matmul(X, W)+b)\n",
    "    cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(hypothesis), axis=1))\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "    # Correct prediction test model\n",
    "    prediction = tf.argmax(hypothesis, 1)\n",
    "    is_correct = tf.equal(prediction, tf.argmax(Y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "    # Launch graph\n",
    "    with tf.Session() as sess:\n",
    "        # initialize tensorflow variables\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for step in range(201):\n",
    "            cost_val, W_val, _ = sess.run([cost, W, optimizer], feed_dict={X: x_data, Y: y_data})\n",
    "            if(step%50==0):\n",
    "                print(\"step: \", step, \"\\ncost: \", cost_val, \"\\nW: \\n\", W_val, \"\\n\")\n",
    "\n",
    "        # predict\n",
    "        print(\"Prediction:\", sess.run(prediction, feed_dict={X: x_test}))\n",
    "        # Calculate the accuracy\n",
    "        print(\"Accuracy: \", sess.run(accuracy, feed_dict={X: x_test, Y: y_test}))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## learning_rate 결과 분석\n",
    "\n",
    "### learning_rate=10.0\n",
    "- 위 실험에서 learning_rate=1.5인 경우 중간부터 `nan`이라는 값이 나오기 시작한다.\n",
    "- `nan`은 not a number라는 뜻으로 이때부터는 더이상 학습을 포기한다.\n",
    "- 이는 learning rate가 너무 커서 값이 발산하는 것!\n",
    "- nan이 나오기 시작한다면 learning rate를 줄여보자!\n",
    "\n",
    "### learning_rate=1e-100\n",
    "- cost의 변화가 거의 없다!\n",
    "- 이 경우, local minima에 빠져있을 확률이 많다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize inputs (min-max scale)\n",
    "\n",
    "아래 그림 좌측과 같이 입력된 데이터가 너무 크거나 너무 작은 값들이 섞여있거나, 데이터가 들쭉날쭉한 경우 등의 경우 gradient descent가 잘 되지 않을 수 있다. 이 경우 normalize를 통해 해결할 수 있다.\n",
    "\n",
    "![normalize-inputs](images/lab7/normalize-inputs.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAD8CAYAAACyyUlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAAGOVJREFUeJzt3X+s3XWd5/HniyKudVRA7hJCKWW0Y1ImmwonyMbRODpCYY3FDXEhXem6rNUoG103GXH6B66Oic7GcWPWYVKFscx2QAZlaDYoNkjG3WRQbpXllzpckB9tkHYowrid6KLv/eN8rp5ee3+033vvuef2+UhOzve8v5/v9/u+N8199fv9fs45qSokSeriuGE3IEkafYaJJKkzw0SS1JlhIknqzDCRJHVmmEiSOjNMJEmdGSaSpM4ME0lSZ8cPu4HFcsopp9SaNWuG3YYkjZTdu3f/Q1WNzTbumAmTNWvWMD4+Puw2JGmkJHl8LuO8zCVJ6swwkSR1ZphIkjozTCRJnRkmkqTODJPlZMcOWLMGjjuu/7xjx7A7knSMOGamBi97O3bAli1w8GD/9eOP918DbNo0vL4kHRM8M1kutm79dZBMOniwX5ekBWaYLBdPPHFkdUmaR4bJcrF69ZHVJWkeGSbLxSc/CStXHlpbubJfl6QFZpgsF5s2wbZtcOaZkPSft23z5rukReFsruVk0ybDQ9JQzHpmkuT6JPuSPDBQ+3KSe9vjsST3tvqaJP80sO7PB7Y5N8n9SSaSfC5JWv3kJLuSPNyeT2r1tHETSe5Lcs7Avja38Q8n2TyfvxBJ0pGby2WuLwEbBgtV9W+qan1VrQe+Anx1YPUjk+uq6n0D9WuB9wBr22Nyn1cDd1bVWuDO9hrgooGxW9r2JDkZuAZ4HXAecM1kAEmShmPWMKmqbwEHDreunV28E7hxpn0kOQ14eVXdXVUF3ABc0lZvBLa35e1T6jdU393AiW0/FwK7qupAVT0L7GJK2EmSFlfXG/BvAJ6uqocHamcl+V6Sv03yhlY7HdgzMGZPqwGcWlVPteUfA6cObPPkYbaZri5JGpKuN+Av59CzkqeA1VX1TJJzgb9JcvZcd1ZVlaQ69vQrSbbQv0TGat9vIUkL5qjPTJIcD/xr4MuTtar6WVU905Z3A48AvwPsBVYNbL6q1QCebpevJi+H7Wv1vcAZh9lmuvpvqKptVdWrqt7Y2KxfYSxJOkpdLnP9AfCDqvrV5askY0lWtOXfpn/z/NF2Gev5JOe3+yxXALe1zXYCkzOyNk+pX9FmdZ0PPNf2cwdwQZKT2o33C1pNkjQks17mSnIj8CbglCR7gGuq6jrgMn7zxvsbgY8n+X/AL4H3VdXkzfv3058Z9hLga+0B8Cng5iRXAo/Tv6EPcDtwMTABHATeDVBVB5J8Arinjfv4wDEkSUOQ/uSq5a/X69X4+Piw25CkkZJkd1X1Zhvnx6lIkjozTCRJnRkmkqTODBNJUmeGiSSpM8NEktSZYSJJ6swwkSR1ZphIkjozTCRJnRkmkqTODBNJUmeGiSSpM8NEktSZYSJJ6swwkSR1ZphIkjozTCRJnc0aJkmuT7IvyQMDtY8l2Zvk3va4eGDdR5NMJPlhkgsH6htabSLJ1QP1s5J8u9W/nOSEVn9xez3R1q+Z7RiSpOGYy5nJl4ANh6l/tqrWt8ftAEnWAZcBZ7dt/izJiiQrgM8DFwHrgMvbWIBPt329GngWuLLVrwSebfXPtnHTHuPIfmxJ0nyaNUyq6lvAgTnubyNwU1X9rKp+BEwA57XHRFU9WlU/B24CNiYJ8Gbglrb9duCSgX1tb8u3AG9p46c7hiRpSLrcM7kqyX3tMthJrXY68OTAmD2tNl39lcBPquqFKfVD9tXWP9fGT7cvSdKQHG2YXAu8ClgPPAV8Zt46mkdJtiQZTzK+f//+YbcjScvWUYVJVT1dVb+oql8CX+DXl5n2AmcMDF3VatPVnwFOTHL8lPoh+2rrX9HGT7evw/W5rap6VdUbGxs7mh9VkjQHRxUmSU4bePkOYHKm107gsjYT6yxgLfAd4B5gbZu5dQL9G+g7q6qAu4BL2/abgdsG9rW5LV8KfLONn+4YkqQhmcvU4BuBvwNek2RPkiuBP0lyf5L7gN8H/hNAVT0I3Aw8BHwd+EA7g3kBuAq4A/g+cHMbC/AR4MNJJujfE7mu1a8DXtnqHwaunukYHX8PGoYdO2DNGjjuuP7zjh3D7kjSUUr/P/vLX6/Xq/Hx8WG3oUk7dsCWLXDw4K9rK1fCtm2wadPw+pJ0iCS7q6o32zjfAa/h2Lr10CCB/uutW4fTj6RODBMNxxNPHFld0pJmmGg4Vq8+srqkJc0w0XB88pP9eySDVq7s1yXNj0Wc5GKYaDg2berfbD/zTEj6z958l+bP5CSXxx+Hqv7zli0LFijO5pKk5WjNmn6ATHXmmfDYY3PejbO5JOlYtsiTXAwTSVqOFnmSi2EiScvRIk9yMUwkaTla5Ekux88+RJI0kjZtWrQZkp6ZSJI6M0wkSZ0ZJpKkzgwTSVJnhokkqTPDRJLUmWEiSepsLt8Bf32SfUkeGKj91yQ/SHJfkluTnNjqa5L8U5J72+PPB7Y5t31v/ESSzyVJq5+cZFeSh9vzSa2eNm6iHeecgX1tbuMfTrJ5Pn8hkqQjN5czky8BG6bUdgG/W1X/Avh74KMD6x6pqvXt8b6B+rXAe4C17TG5z6uBO6tqLXBnew1w0cDYLW17kpwMXAO8DjgPuGYygCRJwzFrmFTVt4ADU2rfqKoX2su7gVUz7SPJacDLq+ru6n/m/Q3AJW31RmB7W94+pX5D9d0NnNj2cyGwq6oOVNWz9INtathJkhbRfNwz+ffA1wZen5Xke0n+NskbWu10YM/AmD2tBnBqVT3Vln8MnDqwzZOH2Wa6uiRpSDp9NleSrcALwORXdz0FrK6qZ5KcC/xNkrPnur+qqiTz9m1dSbbQv0TGar9bXJIWzFGfmST5d8DbgE3t0hVV9bOqeqYt7wYeAX4H2Muhl8JWtRrA0+3y1eTlsH2tvhc44zDbTFf/DVW1rap6VdUbGxs7yp9UkjSbowqTJBuAPwTeXlUHB+pjSVa05d+mf/P80XYZ6/kk57dZXFcAt7XNdgKTM7I2T6lf0WZ1nQ881/ZzB3BBkpPajfcLWk3SKNqxo/8Vs8cd139eoO8o18Kay9TgG4G/A16TZE+SK4H/DrwM2DVlCvAbgfuS3AvcAryvqiZv3r8f+CIwQf+MZfI+y6eAtyZ5GPiD9hrgduDRNv4LbXva/j4B3NMeHx84hqRR+uO8Ywds2dL/rvKq/vOWLUu7Zx1W2hWqZa/X69X4+Piw25AW1uQf54MHf11buXJBvxSpkzVr+gEy1ZlnwmOPLXY3Oowku6uqN9s43wEvLSdbtx4aJNB/vXXrcPqZzRNPHFldS5ZhIi0no/bHebpZls6+HDmGibScjNof509+sn8ZbtDKlf26RophIi0no/bHedOm/v2cM8+EpP+8VO/vaEad3rQoaYmZ/CO8dWv/0tbq1f0gWcp/nDdtWtr9aU4ME2m58Y+zhsDLXJKkzgwTSVJnhokkzdUofbrAIvOeiSTNxdRPF5j86BfwHhWemUjS3IzapwssMsNEkuZi1D5dYJEZJpI0F6P26QKLzDCRpLkYtU8XWGSGiSTNhR/9MiNnc0nSXPnpAtPyzESS1JlhIknqbE5hkuT6JPuSPDBQOznJriQPt+eTWj1JPpdkIsl9Sc4Z2GZzG/9wks0D9XOT3N+2+VySHO0xpAXhO5+lGc31zORLwIYptauBO6tqLXBnew1wEbC2PbYA10I/GIBrgNcB5wHXTIZDG/Oege02HM0xpAUx+c7nxx+Hql+/89lAkX5lTmFSVd8CDkwpbwS2t+XtwCUD9Ruq727gxCSnARcCu6rqQFU9C+wCNrR1L6+qu6uqgBum7OtIjiHNP9/5LM2qyz2TU6vqqbb8Y+DUtnw68OTAuD2tNlN9z2HqR3MMaf75zmdpVvNyA76dUdR87Gs+j5FkS5LxJOP79+9foM607PnOZ2lWXcLk6clLS+15X6vvBc4YGLeq1WaqrzpM/WiOcYiq2lZVvarqjY2NHfEPKAG+81magy5hshOYnJG1GbhtoH5Fm3F1PvBcu1R1B3BBkpPajfcLgDvauueTnN9mcV0xZV9Hcgxp/vnOZ2lWc3oHfJIbgTcBpyTZQ39W1qeAm5NcCTwOvLMNvx24GJgADgLvBqiqA0k+AdzTxn28qiZv6r+f/oyxlwBfaw+O9BjSgvGdz9KM0r8Vsfz1er0aHx8fdhuSNFKS7K6q3mzjfAe8JKkzw0SS1JlhMhs/RkOSZuVH0M9k8mM0Jt/9PPkxGuDNWEka4JnJTPwYDUmaE8NkJn6MhiTNiWEyEz9GQ5LmxDCZiR+jIUlzYpjMxI/RkKQ5cTbXbPwYDUmalWcmkqTODBNJUmeGiSSpM8NEktSZYSJJ6swwkSR1ZphIkjozTCRJnR11mCR5TZJ7Bx7PJ/lQko8l2TtQv3hgm48mmUjywyQXDtQ3tNpEkqsH6mcl+XarfznJCa3+4vZ6oq1fc7Q/hySpu6MOk6r6YVWtr6r1wLnAQeDWtvqzk+uq6naAJOuAy4CzgQ3AnyVZkWQF8HngImAdcHkbC/Dptq9XA88CV7b6lcCzrf7ZNk6SNCTzdZnrLcAjVfX4DGM2AjdV1c+q6kfABHBee0xU1aNV9XPgJmBjkgBvBm5p228HLhnY1/a2fAvwljZekjQE8xUmlwE3Dry+Ksl9Sa5PclKrnQ48OTBmT6tNV38l8JOqemFK/ZB9tfXPtfGSpCHoHCbtPsbbgb9upWuBVwHrgaeAz3Q9xtFKsiXJeJLx/fv3D6sNSVr25uPM5CLgu1X1NEBVPV1Vv6iqXwJfoH8ZC2AvcMbAdqtabbr6M8CJSY6fUj9kX239K9r4Q1TVtqrqVVVvbGys8w8qSTq8+QiTyxm4xJXktIF17wAeaMs7gcvaTKyzgLXAd4B7gLVt5tYJ9C+Z7ayqAu4CLm3bbwZuG9jX5rZ8KfDNNl6SNASdvs8kyUuBtwLvHSj/SZL1QAGPTa6rqgeT3Aw8BLwAfKCqftH2cxVwB7ACuL6qHmz7+ghwU5I/Br4HXNfq1wF/mWQCOEA/gCRJQ5Jj5T/0vV6vxsfHh92GJI2UJLurqjfbON8BL0nqzDCRJHVmmEiSOjNMJEmdGSaSpM4ME0lSZ4aJJKkzw0SS1JlhIknqzDCRJHVmmEiSOjNMJEmdGSaSpM4ME0lSZ4aJJKkzw0SS1JlhIknqzDCRJHXWOUySPJbk/iT3JhlvtZOT7ErycHs+qdWT5HNJJpLcl+Scgf1sbuMfTrJ5oH5u2/9E2zYzHUOStPjm68zk96tq/cD3BF8N3FlVa4E722uAi4C17bEFuBb6wQBcA7wOOA+4ZiAcrgXeM7DdhlmOIUlaZAt1mWsjsL0tbwcuGajfUH13AycmOQ24ENhVVQeq6llgF7ChrXt5Vd1dVQXcMGVfhzuGJGmRzUeYFPCNJLuTbGm1U6vqqbb8Y+DUtnw68OTAtntabab6nsPUZzqGJGmRHT8P+/i9qtqb5J8Du5L8YHBlVVWSmofjTGu6Y7Rw2wKwevXqhWxBko5pnc9Mqmpve94H3Er/nsfT7RIV7XlfG74XOGNg81WtNlN91WHqzHCMwd62VVWvqnpjY2NdfkxJ0gw6hUmSlyZ52eQycAHwALATmJyRtRm4rS3vBK5os7rOB55rl6ruAC5IclK78X4BcEdb93yS89ssrium7Otwx5AkLbKul7lOBW5ts3WPB/6qqr6e5B7g5iRXAo8D72zjbwcuBiaAg8C7AarqQJJPAPe0cR+vqgNt+f3Al4CXAF9rD4BPTXMMSdIiS3+S1PLX6/VqfHx82G1I0khJsnvgbR/T8h3wkqTODBNJUmeGiSSpM8NEktSZYSJJ6swwkSR1ZphIkjozTCRJnRkmkqTODBNJUmeGiSSpM8NEktSZYSJJ6swwkSR1ZphIkjozTCRJnRkmkqTODBNJUmdHHSZJzkhyV5KHkjyY5IOt/rEke5Pc2x4XD2zz0SQTSX6Y5MKB+oZWm0hy9UD9rCTfbvUvJzmh1V/cXk+09WuO9ueQJHXX5czkBeA/V9U64HzgA0nWtXWfrar17XE7QFt3GXA2sAH4syQrkqwAPg9cBKwDLh/Yz6fbvl4NPAtc2epXAs+2+mfbOEnSkBx1mFTVU1X13bb8j8D3gdNn2GQjcFNV/ayqfgRMAOe1x0RVPVpVPwduAjYmCfBm4Ja2/XbgkoF9bW/LtwBvaeMlSUMwL/dM2mWm1wLfbqWrktyX5PokJ7Xa6cCTA5vtabXp6q8EflJVL0ypH7Kvtv65Nl6SNASdwyTJbwFfAT5UVc8D1wKvAtYDTwGf6XqMDr1tSTKeZHz//v3DakOSlr1OYZLkRfSDZEdVfRWgqp6uql9U1S+BL9C/jAWwFzhjYPNVrTZd/RngxCTHT6kfsq+2/hVt/CGqaltV9aqqNzY21uVHlSTNoMtsrgDXAd+vqj8dqJ82MOwdwANteSdwWZuJdRawFvgOcA+wts3cOoH+TfqdVVXAXcClbfvNwG0D+9rcli8FvtnGS5KG4PjZh0zr9cC7gPuT3Ntqf0R/NtZ6oIDHgPcCVNWDSW4GHqI/E+wDVfULgCRXAXcAK4Drq+rBtr+PADcl+WPge/TDi/b8l0kmgAP0A0iSNCQ5Vv5D3+v1anx8fNhtSNJISbK7qnqzjfMd8JKkzgwTSVJnhokkqTPDRJLUmWEiSerMMJEkdWaYSJI6M0wkSZ0ZJpKkzgwTSVJnhokkqTPDRJLUmWEiSerMMJEkdWaYSJI6M0wkSZ0ZJpKkzgwTSVJnIx0mSTYk+WGSiSRXD7sfSTpWjWyYJFkBfB64CFgHXJ5k3bwf6OyzIfn14+yz5/0Q82aUeoXR6tdeF84o9TtKvcKi9juyYQKcB0xU1aNV9XPgJmDjvB7h7LPhoYcOrT300NL8BzRKvcJo9WuvC2eU+h2lXmHR+01VLciOF1qSS4ENVfUf2ut3Aa+rqqsON77X69X4+PiRHmT6dUvt9zZKvcJo9WuvC2eU+h2lXmHe+k2yu6p6s40b5TOTWSXZkmQ8yfj+/fuH3Y4kLVujHCZ7gTMGXq9qtV+pqm1V1auq3tjY2KI2J0nHklEOk3uAtUnOSnICcBmwc16PsG6a+/nT1YdplHqF0erXXhfOKPU7Sr3Covc7smFSVS8AVwF3AN8Hbq6qB+f1IA8++Ju/+HXr+vWlZpR6hdHq114Xzij1O0q9wqL3O7I34I/UUd2Al6RjnDfgJUmLxjCRJHVmmEiSOjNMJEmdGSaSpM6OmdlcSfYDj3fYxSnAP8xTOwttlHqF0erXXhfOKPU7Sr1Ct37PrKpZ3/V9zIRJV0nG5zI9bikYpV5htPq114UzSv2OUq+wOP16mUuS1JlhIknqzDCZu23DbuAIjFKvMFr92uvCGaV+R6lXWIR+vWciSerMMxNJUmeGySySbEjywyQTSa4edj8zSXJ9kn1JHhh2L7NJckaSu5I8lOTBJB8cdk8zSfLPknwnyf9p/f6XYfc0myQrknwvyf8cdi+zSfJYkvuT3JtkSX8ia5ITk9yS5AdJvp/kXw67p+kkeU37nU4+nk/yoQU5lpe5ppdkBfD3wFuBPfS/Q+Xyqnpoxg2HJMkbgZ8CN1TV7w67n5kkOQ04raq+m+RlwG7gkiX8uw3w0qr6aZIXAf8b+GBV3T3k1qaV5MNAD3h5Vb1t2P3MJMljQK+qlvx7N5JsB/5XVX2xfZfSyqr6ybD7mk37e7aX/tebd3nP3WF5ZjKz84CJqnq0qn4O3ARsHHJP06qqbwEHht3HXFTVU1X13bb8j/S/k+b04XY1ver7aXv5ovZYsv8TS7IK+FfAF4fdy3KS5BXAG4HrAKrq56MQJM1bgEcWIkjAMJnN6cCTA6/3sIT/4I2qJGuA1wLfHm4nM2uXje4F9gG7qmop9/vfgD8EfjnsRuaogG8k2Z1ky7CbmcFZwH7gL9olxC8meemwm5qjy4AbF2rnhomGKslvAV8BPlRVzw+7n5lU1S+qaj2wCjgvyZK8lJjkbcC+qto97F6OwO9V1TnARcAH2iXbpeh44Bzg2qp6LfB/gSV9LxWgXY57O/DXC3UMw2Rme4EzBl6vajXNg3bv4SvAjqr66rD7mat2WeMuYMOwe5nG64G3t/sQNwFvTvI/htvSzKpqb3veB9xK/xLzUrQH2DNwVnoL/XBZ6i4CvltVTy/UAQyTmd0DrE1yVkv2y4CdQ+5pWWg3tK8Dvl9VfzrsfmaTZCzJiW35JfQnZfxguF0dXlV9tKpWVdUa+v9mv1lV/3bIbU0ryUvbJAzaJaMLgCU5I7Gqfgw8meQ1rfQWYElOGpnichbwEhf0T9k0jap6IclVwB3ACuD6qnpwyG1NK8mNwJuAU5LsAa6pquuG29W0Xg+8C7i/3YcA+KOqun2IPc3kNGB7mxFzHHBzVS35Kbcj4lTg1v7/Lzge+Kuq+vpwW5rRfwR2tP9gPgq8e8j9zKgF9FuB9y7ocZwaLEnqystckqTODBNJUmeGiSSpM8NEktSZYSJJ6swwkSR1ZphIkjozTCRJnf1/5damgqQAxn4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11d60a208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1208dab00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def MinMaxScaler(data):\n",
    "    numerator = data - np.min(data, 0)\n",
    "    denominator = np.max(data, 0) - np.min(data, 0)\n",
    "\n",
    "    # noise term prevents the zero division\n",
    "    return numerator / (denominator + 1e-7)\n",
    "\n",
    "xy = np.array([[828.659973, 833.450012, 908100, 828.349976, 831.659973],\n",
    "               [823.02002, 828.070007, 1828100, 821.655029, 828.070007],\n",
    "               [819.929993, 824.400024, 1438100, 818.97998, 824.159973],\n",
    "               [816, 820.958984, 1008100, 815.48999, 819.23999],\n",
    "               [819.359985, 823, 1188100, 818.469971, 818.97998],\n",
    "               [819, 823, 1198100, 816, 820.450012],\n",
    "               [811.700012, 815.25, 1098100, 809.780029, 813.669983],\n",
    "               [809.51001, 816.659973, 1398100, 804.539978, 809.559998]])\n",
    "\n",
    "# before normalize\n",
    "plt.plot(xy, 'ro')\n",
    "plt.show()\n",
    "\n",
    "# after normalize\n",
    "normalized_ = MinMaxScaler(xy)\n",
    "plt.plot(normalized_, 'bo')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 빨간 점 그래프는 normalize되지 않은 그래프이며, 파란 점 그래프는 normalize된 그래프이다. 기존 0~1,750,000이었던 그래프가 0.0~1.0 사이로 normalize가 되었다.\n",
    "\n",
    "normalize된 데이터는 gradient descent가 더 잘 된다!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
