{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Softmax classification\n",
    "\n",
    "- [강의 동영상 6-1](https://youtu.be/MFAnsx1y9ZI): Multinomial classification\n",
    "- [강의 동영상 6-2](https://youtu.be/jMU9G5WEtBc): Softmax and Cost function\n",
    "- [강의 슬라이드 6-1, 6-2](https://hunkim.github.io/ml/lec6.pdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Classification\n",
    "- 여러개의 클래스가 있을 때\n",
    "\n",
    "### 박스 그래프에서 기호의 의미\n",
    "- $\\bar{Y} = H(x)$로써 예측값을 의미하며, $Y$는 실제값을 의미한다. $(Y\\neq \\bar{Y})$\n",
    "- $\\int$ 모양은 sigmoid의 symbol\n",
    "\n",
    "### Binary Classification의 경우\n",
    "\"W를 학습한다\", \"또는 logistic classification을 학습시킨다\"\n",
    "- = 두 class를 구분하는 선을 긋는다(찾아낸다)고 생각하면 된다.\n",
    "\n",
    "\n",
    "### Multinomial Classification의 경우\n",
    "\"W를 학습한다\", \"또는 logistic classification을 학습시킨다\"\n",
    "- = 여러 class를 구분하는 선을 여러개 긋는다(찾아낸다)고 생각하면 된다.\n",
    "- = binary classification을 class만큼 수행한다.\n",
    "\n",
    "![multinomial classification](images/lec6/multinomial_classification.png)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SOFTMAX\n",
    "- 각 벡터를 다 더했을 때 1이 되도록 해주는 함수(각각을 확률로 나타내므로 합이 1이 된다.)\n",
    "- 그 중 ONE-HOT ENCODING을 사용하면 가장 확률이 높은 것을 1.0으로 나머지를 0으로 만들어준다. tensorflow에서는 argmax\n",
    "\n",
    "### Cost function\n",
    "- Cross-entropy cost function\n",
    "- 예측한 값이 맞으면 0에 가까워지고, 틀리면 무한대에 가까워진다.\n",
    "\n",
    "### Logistic cost VS Cross entropy\n",
    "\n",
    "$$\n",
    "C(H(x), y) = \\begin{cases}\n",
    "-log(H(x)) & : y=1 \\\\\n",
    "-log(1-H(x)) & : y=0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "$$\n",
    "D(S, L) = -\\sum_{i} L_{i} \\cdot log(S_{i})\n",
    "$$\n",
    "\n",
    "Logistic cost에서 보았던 H(X) = S, y = L 이므로 결국 Logistic cost = Cross entropy\n",
    "\n",
    "### Cost function \n",
    "$$\n",
    "Cost(Loss) = \\frac{1}{N}\\cdot \\sum D(S(W X_{i}+b), L_{i})\n",
    "$$\n",
    "- 이것도 gradient descent 적용 가능!\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
